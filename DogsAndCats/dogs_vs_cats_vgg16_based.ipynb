{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%ls data/dogscats_new\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_path = \"data/dogscats_new/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.optimizers import  Adam\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "# Get data for training and validation\n",
    "Import and init ImageData generator for future image processing from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_imgs = ImageDataGenerator()\n",
    "valid_imgs = ImageDataGenerator()\n",
    "test_imgs = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load VGG16 keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vgg16 = VGG16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Remove last layer from vgg16\n",
    "Since this model is based on imagenet but we want to have only 2 categories instead for 1000 like imagenet have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "vgg16.layers.pop()\n",
    "for layer in vgg16.layers: \n",
    "    layer.trainable=False\n",
    "\n",
    "last = vgg16.layers[-1].output\n",
    "x = Dense(2, activation=\"softmax\")(last)\n",
    "model = Model(vgg16.input, x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img_size = 224 # because vgg16 input is 224,244,3 ; 3 here is for RGB \n",
    "batch_size = 64\n",
    "img_batch_size = 8\n",
    "train_imgs_gen = train_imgs.flow_from_directory(data_path + \"train\", \n",
    "                                                target_size=(img_size,img_size), \n",
    "                                                batch_size=img_batch_size,\n",
    "                                                color_mode = \"rgb\",\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=True)\n",
    "\n",
    "valid_imgs_gen = valid_imgs.flow_from_directory(data_path + \"valid\", \n",
    "                                                target_size=(img_size,img_size), \n",
    "                                                batch_size=img_batch_size,\n",
    "                                                color_mode = \"rgb\",\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=True)\n",
    "\n",
    "test_imgs_gen = test_imgs.flow_from_directory(data_path + \"test\",\n",
    "                                              target_size=(img_size,img_size), \n",
    "                                              batch_size=img_batch_size,\n",
    "                                              color_mode = \"rgb\",\n",
    "                                              class_mode=None,\n",
    "                                              shuffle=False)\n",
    "#model.load_weights('my_custom_vgg16_model_sgd_4.weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for count in range(5):\n",
    "    model.fit_generator(  train_imgs_gen, \n",
    "                          samples_per_epoch= train_imgs_gen.nb_sample,\n",
    "                          nb_epoch = 1,\n",
    "                          validation_data = valid_imgs_gen,\n",
    "                          nb_val_samples = valid_imgs_gen.nb_sample\n",
    "                         )\n",
    "    model.save_weights(f'my_custom_vgg16_model_adam_{count}.weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = cv2.imread('./data/dogscats_new/test/unknown/333.jpg')\n",
    "img=cv2.resize(img,(224,224))\n",
    "img=np.array(img).reshape((224,224,3))\n",
    "plt.imshow(img)\n",
    "img = img.reshape((1,) + img.shape)\n",
    "np.rint(model.predict(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_gen = model.predict_generator(test_imgs_gen, test_imgs_gen.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "submission_file_name = 'submission_vgg16_5epoch.csv'\n",
    "filenames = test_imgs_gen.filenames\n",
    "ids = np.array([int(f[8:f.find('.')]) for f in filenames])\n",
    "isdog = model_gen[:,1]\n",
    "isdog = isdog.clip(min=0.05, max=0.95)\n",
    "subm = np.stack([ids,isdog], axis=1)\n",
    "subm[:5]\n",
    "np.savetxt(submission_file_name, subm, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(submission_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
